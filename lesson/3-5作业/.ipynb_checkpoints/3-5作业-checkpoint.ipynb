{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【任务1】"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**任务名称：**  \n",
    "nn.Module与网络模型构建步骤；模型容器与AlexNet构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**任务简介：**  \n",
    "学习nn.Module类以及搭建网络模型步骤；熟悉搭建网络模型时常用的模型容器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**详细说明：**  \n",
    "\n",
    "本节第一部分介绍网络模型的基本类nn.Module，nn.Module是所有网络层的基本类，它拥有8个有序字典，用于管理模型属性，本节课中将要学习如何构建一个Module。  \n",
    "然后通过网络结构和计算图两个角度去观察搭建一个网络模型需要两个步骤：第一步，搭建子模块；第二步，拼接子模块。  \n",
    "\n",
    "本节第二部分介绍搭建网络模型常用的容器，如Sequential，ModuleList, ModuleDict，然后学习pytorch提供的Alexnet网络模型结构加深对模型容器的认识。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**作业名称（详解）：**  \n",
    "\n",
    "1. 采用步进(Step into)的调试方法从创建网络模型开始（net = LeNet(classes=2)）进入到每一个被调用函数，观察net的_modules字段何时被**构建**并且**赋值**，记录其中所有进入的类与函数   \n",
    "   例如：  \n",
    "   第一步：net = LeNet(classes=2)  \n",
    "   第二步：LeNet类，__init__()，super(LeNet, self).__init__()  \n",
    "   第三步: Module类, ......  \n",
    "   第n步：返回net  \n",
    "\n",
    "2. 采用sequential容器，改写Alexnet，给features中每一个网络层增加名字，并通过下面这行代码打印出来  \n",
    "   print(alexnet._modules['features']._modules.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 采用步进(Step into)的调试方法从创建网络模型开始（net = LeNet(classes=2)）进入到每一个被调用函数，观察net的_modules字段何时被**构建**并且**赋值**，记录其中所有进入的类与函数  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step1: net = LeNet(classes=2)\n",
    "\n",
    "Step2: lenet.py, LeNet类，init函数 -> 运行完init后就会跳回，这时候已经创建好了模型\n",
    "\n",
    "Step3: output = net(input) -> module类里的_call_impl函数\n",
    "\n",
    "Step4: 找到forward函数 -> 进入了LeNet中的自己写的forward实现前向传播，执行完后会得到output返回到最开始调用的位置\n",
    "\n",
    "_modules字段何时被构建及赋值：\n",
    "\n",
    "进入LeNet的init后，进入super后，进入了module的init，这里会进行8个参数的初始化其中就包括了_modules。\n",
    "\n",
    "下面每一次构建网络层都会进入Conv2d类的init函数，这里是继承了convNd类，ConvNd类继承了Module类，进行开始构建这一层网络，构建完毕后回到LeNet会发现已经出现了这一层网络结构\n",
    "\n",
    "_modules存储的是网络子结构，没有字结构了就是空的，每一层网络层也是一个module也是有_modules的\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 采用sequential容器，改写Alexnet，给features中每一个网络层增加名字，并通过下面这行代码打印出来  \n",
    "   print(alexnet._modules['features']._modules.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【任务2】"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**任务名称：**  \n",
    "学习网络层中的卷积层，池化层，全连接层和激活函数层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**任务简介：**  \n",
    "学习网络模型中采用的神经网络层，包括卷积层，池化层，全连接层和激活函数层，学会如何区分二维卷积和三维卷积；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**详细说明：**  \n",
    "本节第一部分学习卷积神经网络中最重要的卷积层，了解卷积操作的过程与步骤，同时学会区分一维/二维/三维卷积，最后学习转置卷积（Transpose Convolution）的由来以及实现方法；  \n",
    "\n",
    "本节第二部分学习池化层，全连接层和激活函数层，在池化层中有正常的最大值池化，均值池化，还有图像分割任务中常用的反池化——MaxUnpool，在激活函数中会学习Sigmoid,Tanh和Relu，以及Relu的各种变体，如LeakyReLU，PReLU， RReLU   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**作业名称（详解）：**  \n",
    "\n",
    "1. 深入理解二维卷积，采用手算的方式实现以下卷积操作，然后**用代码验证**  \n",
    "   1）采用2个尺寸为3*3的卷积核对3通道的5*5图像进行卷积，padding=0，stride=1，dilation=0  \n",
    "   其中 input shape = （3， 5， 5）,\n",
    "   kernel size = 3*3，第一个卷积核所有权值均为1，第二个卷积核所有权值均为2，  \n",
    "   **计算输出的feature map尺寸以及所有像素值**  \n",
    "     2）接1）题，上下左右四条边均采用padding，padding=1，填充值为0，计算输出的feature map尺寸以及所有像素值  \n",
    "\n",
    "2. 对lena图进行3*3*33d卷积，提示：padding=（1， 0， 0）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 深入理解二维卷积，采用手算的方式实现以下卷积操作，然后**用代码验证**  \n",
    "\n",
    "   1）采用2个尺寸为 3X3 的卷积核对3通道的 5X5 图像进行卷积，padding=0，stride=1，dilation=0  \n",
    "     其中 input shape = （3， 5， 5）,kernel size = 3X3，第一个卷积核所有权值均为1，第二个卷积核所有权值均为2， \n",
    "     **计算输出的feature map尺寸以及所有像素值** \n",
    "   \n",
    "   2）接1）题，上下左右四条边均采用padding，padding=1，填充值为0，计算输出的feature map尺寸以及所有像素值 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Week](./Week3_3.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.],\n",
      "          [2., 2., 2., 2., 2.]],\n",
      "\n",
      "         [[3., 3., 3., 3., 3.],\n",
      "          [3., 3., 3., 3., 3.],\n",
      "          [3., 3., 3., 3., 3.],\n",
      "          [3., 3., 3., 3., 3.],\n",
      "          [3., 3., 3., 3., 3.]]]])\n",
      "torch.Size([1, 1, 5, 5])\n",
      "tensor([[[[24.0905, 36.0905, 36.0905, 36.0905, 24.0905],\n",
      "          [36.0905, 54.0905, 54.0905, 54.0905, 36.0905],\n",
      "          [36.0905, 54.0905, 54.0905, 54.0905, 36.0905],\n",
      "          [36.0905, 54.0905, 54.0905, 54.0905, 36.0905],\n",
      "          [24.0905, 36.0905, 36.0905, 36.0905, 24.0905]]]],\n",
      "       grad_fn=<MkldnnConvolutionBackward>)\n",
      "torch.Size([1, 1, 5, 5])\n",
      "tensor([[[[ 47.9164,  71.9164,  71.9164,  71.9164,  47.9164],\n",
      "          [ 71.9164, 107.9164, 107.9164, 107.9164,  71.9164],\n",
      "          [ 71.9164, 107.9164, 107.9164, 107.9164,  71.9164],\n",
      "          [ 71.9164, 107.9164, 107.9164, 107.9164,  71.9164],\n",
      "          [ 47.9164,  71.9164,  71.9164,  71.9164,  47.9164]]]],\n",
      "       grad_fn=<MkldnnConvolutionBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "# conv1 = nn.Conv2d(3, 1, 3)\n",
    "conv1 = nn.Conv2d(3, 1, 3, padding=1)\n",
    "conv1.weight.data = torch.ones(conv1.weight.shape)\n",
    "\n",
    "# conv2 = nn.Conv2d(3, 1, 3)\n",
    "conv2 = nn.Conv2d(3, 1, 3, padding=1)\n",
    "conv2.weight.data = torch.ones(conv2.weight.shape)*2\n",
    "\n",
    "input = torch.ones((3, 5, 5))\n",
    "input = input.unsqueeze(0)\n",
    "\n",
    "input[:,1,:,:] = input[:,1,:,:]*2\n",
    "input[:,2,:,:] = input[:,2,:,:]*3\n",
    "print(input)\n",
    "\n",
    "out1 = conv1(input)\n",
    "print(out1.shape)\n",
    "print(out1)\n",
    "\n",
    "out2 = conv2(input)\n",
    "print(out2.shape)\n",
    "print(out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 对lena图进行3X3X3 3d卷积，提示：padding=（1， 0， 0）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
